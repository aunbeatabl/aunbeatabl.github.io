\documentclass[11pt]{scrartcl}
\usepackage[sexy]{evan(dark)}
\usepackage[bottom]{footmisc}
\newcommand{\heart}{\ensuremath\heartsuit}

\begin{document}
\title{Discrete Math (Math 55) @UC Berkeley} % Beginner
\author{Adrian Fry}
\date{Fall 2024}
\maketitle
\tableofcontents
\pagenumbering{arabic}

\begin{abstract}
    This is my attempt at taking notes for my math class\footnote{we'll see how long this keeps up}: Math 55 @UC Berkeley as taught by Dr. Nikhil Srivastava. \LaTeX  template thanks to Ian Kerio, Evan Chen.  Textbook used is Discrete Mathematics and its applications, by Kenneth Rosen.  Any mistakes are my own
\end{abstract}
\Line \\
\section{Logic}
\subsection{8.29.2024}
\subsubsection{intro}
Discrete math 
\begin{itemize}
    \item integers \mathbb{Z}
    \item graphs
    \item not continuous objects 
\end{itemize}
This class will be built up from scratch (naive set theory)
\subsubsection{Propositional Logic}
\begin{quote}
    "Mathematics is the science that draws necessary conclusions." - B. Pierre
\end{quote}

\begin{definition}[Proposition]
    A \textbf{proposition} is a declarative sentence which is True or False, but not both.
\end{definition}
\begin{example}
    Sentence: Pigs can fly\\
    Proposition? Yes\\
    Truth Value: False\\\\
    Sentence: $x+5=9$\\ Proposition? No
\end{example}

\begin{remark}
    A proposition must be 100\% precisely unambiguous / precisely specified (must agree on the definition)
\end{remark}
There are $3$ basic logical connectives
\begin{itemize}
    \item Negation $\neg$ \begin{definition}[negation]
        The \textbf{negation} of a proposition $p$ is another proposition $\neg p$ that has the opposite truth value of the proposition $p$.
    \end{definition}
\begin{center}
\begin{tabular}{|c|c|}
\hline
$p$ & $\neg p$\\
\hline
T & F\\
\hline 
F & T\\
\hline
\end{tabular}
\end{center}
    \item Conjunction $\wedge$ \begin{definition}[conjunction]
        Given $2$ propositions $p$ and $q$, their \textbf{conjunction} is the proposition "$p$ and $q$" denoted $p \wedge q$, where their conjunction is true only if both $p$ and $q$ are true.
    \end{definition}
\begin{center}
    \begin{tabular}{|c|c|c|}
         \hline
         $p$&$q$&$p\wedge q$  \\
         \hline
         T & T & T\\\hline
         T&F&F\\ \hline
         F&T&F\\ \hline
         F&F&F\\ \hline
    \end{tabular}
\end{center}
    \item Disjunction $\vee$ \begin{definition}[disjunction]
        Given $2$ propositions, their \textbf{disjunction} is "$p$ or $q$" denoted $p\vee q$.  $p\vee q$ is true if at least one of $p$ and $q$ is true, otherwise it is false.
    \end{definition}
\end{itemize}
These $3$ connectives appear throughout mathematics
\begin{definition}[conditional]
    If $p$ and $q$ are propositions, the \textbf{conditional} $p \rightarrow q$ is the statement "$p$ implies $q$", or "if $p$ then $q$"
\end{definition}
\begin{center}
\begin{tabular}{ |c|c|c| } 
 \hline
 $p$ & $q$ & $p \rightarrow q$ \\ 
 \hline
 T & T & T \\ 
 \hline
 T & F & F \\ 
 \hline
 F & T & T\\
 \hline
 F & F & T\\
 \hline
\end{tabular}
\end{center}
\newline
\begin{definition}[converse implication]
    $q\rightarrow p$ is the converse of $p \rightarrow q$
\end{definition}
     
\newline
  
\begin{definition}[biconditional]
    Given $p$, $q$ propoistions, the \textbf{biconditional} proposition "$p$ IFF $q$" is denoted $p \leftrightarrow q$.  So The truth value of the biconditional is T if both $p$ and $q$ have the same truth value.
\end{definition}


\begin{problem}
    Is $p \leftrightarrow q$ the same as $(p \rightarrow q)\wedge (q\rightarrow p)?$

\begin{definition}[equivalence]
    $2$ compound propositions $C_1$, $C_2$ are \textbf{equivalent}, denoted $C_1 \equiv C_2$ if they have the same truth value for all truth values of the propositional variables in them.
\end{definition}
By drawing out a truth table, we can mechanically determine the solution, which is that the $2$ statements are equivalent.
\end{problem}

\begin{remark}
    You might wonder if $C_1 \equiv C_2$ is a proposition?\\
    Notice that if we draw the truth table for this, we can see that it is equivalent to $C_1 \leftrightarrow C_2$, or $\equiv \equiv \leftrightarrow$
\end{remark}

\begin{definition}[Tautology]
    A compound proposition that's always true (for all truth values of its propositional variables) is a called a \textbf{tautology}. 
\end{definition}

\begin{example}[monopoly tautology]
    Consider the statement: "If I rolled the most doubles, then I lost, or if I lost, then I had the least hotels."\\
    This statement is hard to decipher, but we can break it down into a compound proposition, and then determine whether this proposition is a tautology.\\
    Let $d, l, \text{and } h$ be the following propositions:
    $d=$ "I rolled the most doubles."\\
    $l=$ "I lost."\\
    $h=$ "I had the least hotels."\\
    The logical structure of the sentence is: $C = (d\rightarrow l) \vee (l \rightarrow h)$\\
    The truth value of this proposition is always true.
\end{example}
\Line\\
\subsection{9.3.2024}
\subsubsection{More on logical equivalence, Rules of Inference (Propositional logic)}
\begin{remark}[Review]
    Last week we Reasoned about the truth values of propositions without knowing them.
\end{remark}
Below are some examples of equivalence
\begin{example}[1]
    $p \vee \neg p \equiv T$ - Tautology\\
    $p \wedge \neg p \equiv F$ - Contradiction 
\end{example}
\begin{example}[2]
    $p \rightarrow q \equiv (\neg p) \vee q$\\
    "If it rains, I get wet." is equivalent to saying: "It does not rain or I get wet"
\end{example}
\begin{example}[3 - Contrapositive]
    $p\rightarrow q \equiv \neg q \rightarrow \neg p$\\ This becomes a surprisingly powerful tool when writing proofs
\end{example}
\begin{example}[4 - de Morgan's Laws]
    $\neg(p \wedge q) \equiv \neg p\vee \neg q$\\
    $\neg(p\vee q) \equiv \neg p \wedge \neg q$
\end{example}
\begin{remark}[Disjunction Rules]
    If all of the logical connectives in a statement are $\vee$ (or), then the statement is associative - any reordering of parentheses is equivalent.  It is also commutative
\end{remark}
Rules of inference: \begin{itemize}
    \item If $p\wedge (p\rightarrow q) \rightarrow q \equiv T$ (Modus Ponens)
    \item $\neg q \wedge (p\rightarrow q) \equiv neg p$
    \item $(p \rightarrow q) \wedge (q\rightarrow r) \equiv p\rightarrow r$
\end{itemize}
\subsubsection{Predicate Logic}
\begin{remark}[Motivation]
We want to say statements like "Every integer is even or odd".  That is, we want to say things about infinitely many contexts.  Attempting to do this in propositional logic gives (1 is odd $\vee$ 1 is even) $\vee$ (2 is odd $\vee$ 2 is even), and so on.  Which is infinite
\end{remark}

\begin{definition}[Predicate]
    A \textbf{predicate} (aka propositional function), is a statement containing one or more variables from a domain, which becomes a proposition when each variable is instantiated.
\end{definition}
\begin{example}
    Letting $P$ be the predicate, and $x$ the variable, we can write\\
    $P(x)$ is the statement "$x$ is even."\\
    The Domain must be specified so we can write:\\
    $P(x)$ is the statement "$x$ is even when $x\in \mathbb{N}$"\\
    And thus we have $P(2) = $ "$2$ is even," $P(3) =$ "$3$ is even
\end{example}
\begin{example}
    $Q(x, y) = x < y$, with $x, y \in \mathbb{R}$
\end{example}
\begin{definition}[Quantifiers $\forall$ and $\exists$]
    The \textbf{Universal Quantification} of $P(x)$ is the proposition, "For all $x$ in the domain, P(x)." Denoted $\forall$ $x P(x)$ such that $x \in$ domain.\\
    The \textbf{Existential Qualification} of $P(x)$ is the proposition, "There exists some $x$ in the domain such that $P(x)$." Denoted $\exists$ $x P(x)$ such that $x \in$ domain.
\end{definition}
\begin{remark}
    The same statement can be written both using logical notation or in English.
\end{remark}
\Textbf{Terminology}: A variable appearing in a qualifier is \textbf{bound}. Otherwise it is \textbf{free}. A statement in which all variables are bound is a proposition.\\
The professor goes on a tangent about $\forall$ and $\exists$ and what they mean.
\begin{remark}
    If the domain is \textbf{finite}, you can write $\forall$ $x P(x) \equiv P(d_1) \wedge P(d_2) \wedge ... \wedge P(d_n)$\\
    $\exists$ $x P(x) \equiv P(d_1) \vee P(d_2) \vee \ellipses \vee P(d_n)$
\end{remark}
\begin{remark}
    Can use $\rightarrow$, $\wedge$ to specify domain:\\
    $\forall x $ $(x \in \mathbb{Z} \rightarrow P(x) \vee R(x))$\\
    $\exists x$ $(x \in \mathbb{Z} \wedge x^2 = 2)$
\end{remark}
\begin{example}[Negation of Quantifiers]
    "Every integer is prime," or $\forall x \in \mathbb{Z}$, $x \in \mathbb{P}$\\
    "There exists some non-prime integer," or $\exists x\in \mathbb{Z}$ s.t. $x \notin \mathbb{P}$
\end{example}
\begin{definition}[Logical Equivalence for statements in Predicate Logic]
    $2$ propositions with quantifiers are \textbf{logically equivalent}, denoted $C_1 \equiv C_2$ if $\forall$ predicates $\wedge$ $\forall$ domains, they have the same truth value. 
\end{definition}
\begin{remark}[De Morgan for Qualifiers]
    Notice $\neg \forall x P(x) \equiv \exists x \neg P(x)$, and vice versa
\end{remark}
\begin{example}[Nesting of Qualifiers]
    Can write expressions like: $\forall x\text{, } \exists y\text{ s.t. }(x < y)$ where $x, y\in \mathbb{Z}$\\
    But reversing the order of $\forall$ and $\exists$, we get a statement which is false.
\end{example}
\Line
\subsection{9.5.2024}
\subsubsection{Rules of Inference for Quantifiers}
\begin{definition}[instantiation]
    $\forall$ in the domain implies $P(x)\rightarrow$ "$P(x)$ is true for an arbitrary element $a$ of the domain."\\
    $\exists$ in the domain s.t. $P(x)\rightarrow$ "It is possible to choose an element in the domain s.t. $P(x)$ is true."\\
    \\
    The opposite of instantiation is generalization 
\end{definition}

\subsubsection{Direct Proof}
\begin{definition}[Argument]
    An argument is a sequence of propositions, each of which is a premise (assumption) or a conclusion (follows from the previous propositions via the Rules of Inference). 
\end{definition}
An argument is \textbf{valid} is the above property holds
A \textbf{proof} is a valid argument used to establish the truth of a mathematical proposition.
\begin{definition}[Direct Proof]
    Used to prove the statement: $\forall$ $x \in$ Domain, $P(x) \rightarrow Q(x)$
\end{definition}
\begin{example}
    \begin{definition}[Even]
        An integer $n$ is even if there exists an integer $k$ s.t. $n=2k$.
    \end{definition}
    \begin{definition}[Odd]
        $\forall$ $n \in \mathbb{N}$, $n$ is Odd $\leftrightarrow$ it is not Even, or if there exists an integer $k$ s.t. $n=2k+1$
    \end{definition}
    \noindent
    \begin{proposition}[A]
    $\forall$ $n \in$ Odd, $n^2$ is also Odd.\\
    \end{proposition}
    \textbf{Proof}: Let $n\in \mathbb{N}$ and $n$ is odd. By definition, $\exists$ $k \in \mathbb{N}$ s.t. $n=2k+1$ ($\exists$ instantiation). Observe that $$n^2 = (2k+1)^2 = 4k^2 + 4k + 1 = 2(2k^2 + 2k) + 1$$  Let $h =(2k^2 + 2k)$. Since $h \in \mathbb{N}$, we have $n^2 = 2h+1$ and thus is odd($\exists$ generalization).  Thus $\forall$ $n$ odd, $n^2$ is odd. ($\forall$ generalization) \qed
\end{example}
\subsubsection{Contrapositive}
\begin{definition}[Contrapositive]
    $\forall $ $x$, $P(x) \rightarrow Q(x) \equiv$ $\forall$ $x$, $\neg Q(x) \rightarrow \neg P(x)$
\end{definition}
\begin{example}
    \begin{proposition}[B] For every integer $n$, if $n^2$ is odd, then $n$ is also odd
    \end{proposition}
    \textbf{Proof} (by contrapositive): Let $n \in \mathbb{N}$ and $n$ is even. By definition, we can choose $k$ s.t. $n=2k$ ($\exists$ instantiation).  Observe that $$n^2 = (2k)^2 = 4k^2 = 2(2k^2)$$  Thus, $n^2$ is even ($\exists$ generalization), as desired ($\forall$ $n$ even, $n^2$ is even ($\forall$ generalization)).
\end{example}

\subsubsection{Contradiction}
\begin{definition}[Rationals]
    $x \in \mathbb{R}$ has the property $x \in \mathbb{Q}$ if $exists$ $p, q \in \mathbb{N}$ s.t. $x = \frac{p}{q}$
\end{definition}
\begin{definition}[irrational]
    A real number $x$ is irrational if it is not rational.
\end{definition}
\begin{proposition}[C] If $x\in \mathbb{Q}$, we can choose $p, q$ with no common factors s.t. $x = \frac{p}{q}$\\
\end{proposition}
\begin{theorem}[$\sqrt{2}$ is irrational]
    \textbf{Proof}: Assume for contradiction that $\sqrt{2}$ is rational.  Then $\exists$ $p, q \in \mathbb{N}$ s.t. $\sqrt{2} = \frac{p}{q}$. Thus $\sqrt{2}^2 = 2 = \frac{p^2}{q^2}$.  But if $\frac{p^2}{q^2} = 2$, then $p^2 = 2 q^2$, which implies $p^2$ is even, and thus $p$ is even (by \textbf{Proposition} B).   By definition, we can choose come $k$ s.t. $p=2k$. Substituting, we have $(2k)^2 = 2q^2$, thus $q^2 = 2k^2$, so $q^2$ is even, which implies $q$ is even.(by \textbf{Proposition} B) But $p$ and $q$ have no common factors, so we have a contradiction. \qed
\end{theorem}
\noindent
\Line

\subsection{9.10.2024}
\subsubsection{More on Proofs}
\begin{remark}[The bare minimum]
    A good proof is\begin{enumerate}
        \item Clear - every word in the proof is well-defined - variables bound with qualifiers - possible to translate into formal logic
        \item Correct - valid (each line follows from the previous line) - no mistakes
    \end{enumerate}
\end{remark}
\textbf{TIPS}: \begin{itemize}
    \item Use \textit{keywords} to indicate logical structure: \begin{itemize}
        \item Let $x$ be arbitrary.
        \item We can choose $y$ s.t.\ldots
        \item We conclude that\ldots
        \item By definition\ldots
        \item Assume $P(x)$\ldots
    \end{itemize}
    \item A proof has a beginning, middle, and end.  Be aware of where you are \begin{itemize}
        \item Beginning: Assume hypotheses
        \item Middle: Rules of Inference, Observations
        \item End: Conclusion
    \end{itemize}
    \item Use complete sentences
\end{itemize}
\subsubsection{Sets}
\begin{definition}[Set]
    A \textbf{Set} is an unordered "collection" of objects\footnote{We are using naive Set theory and assuming every object is concrete}, which are called its \textbf{elements}.  A set \textbf{contains} its elements. Denoted $x \in A$.
\end{definition}
\textbf{Key Property}: For every $x$, "$x \in A$" is a proposition.\\
\textbf{$2$ ways to specify}\begin{enumerate}
    \item Roster notation: \begin{itemize}
        \item $A = \{1, 2, 5\}$ 
        \item $\mathbb{Z} =$ the set of all integers $= \{0, 1, 2, \ldots\}$
    \end{itemize}  
    \item Set-Builder notation: \begin{itemize}
        \item Given a predicate $P(x)$, $A = \{x:P(x)\}$ is a set.
        \item Even $ = \{x \in \mathbb{Z} : x \text{ is even}\}$
    \end{itemize}
\end{enumerate}
\begin{definition}[The empty set]
    The set with no elements is called the empty set, denoted $\emptyset$
    Formally: $\forall x, (x \notin \emptyset)$
\end{definition}
\begin{definition}[Equality of sets]
    $2$ sets are equal if every element in $1$ is in the other and vice versa.
\end{definition}
\begin{definition}
    Given $A, B$, $A$ is a subset of $B$ denoted $A \subseteq B$ if $\forall x (x\in A \rightarrow x \in B)$
\end{definition}
\textbf{Operations on Sets}: $\cup, \cap, -, \mathcal{P}, \times$
\begin{definition}[Set operations]\\
    $A\cup B = \{x: x\in A \vee x \in B\}$ - Union\\
    $A \cap B = \{x: x\in A \land x \in B\}$ - Intersection\\
    $A-B = \{x:  x\ in A \land x \notin B\}$ - Difference \\
    $\overline{A} = \{x: x \notin A\}$ - Complement
\end{definition}

\begin{definition}[Power set]
    The \textbf{Power Set} of $A$, denoted $\mathcal{P}(A)$ is the set of all subsets of $A$ $$\mathcal{P}(A) = {S:S\subseteq A}$$
\end{definition}
\begin{remark}
    If $A$ has $n$ elements, $\mathcal{P}(A)$ has $2^n$ elements.  
\end{remark}
\begin{definition}[Cartesian Product]
    Given $A, B$, their \textbf{Cartesian Product} is the set of ordered pairs denoted $A \times B = \{(a, b): a \in A \land b \in B\}$
\end{definition}
\begin{example}[are two]
    $\mathbb{R}\times \mathbb{R} = \mathbb{R}^2$
\end{example}
\noindent
\Line
\\
\section{Sets}
\subsection{9.12.2024}
\subsubsection{Functions}
\begin{example}
    $f(x) = x^2$ gives a parabola
\end{example}
\begin{definition}[Function]
    If $A, B$ are nonempty sets, a \textbf{function} from $A$ to $B$ denoted $f: A \rightarrow B$is a rule which assigns exactly one element of $B$ to every element of $A$.  This assignment is denoted $f(a) = b$, where $a \in A$ and $b \in B$.  $A$ is the domain and $B$ is the codomain.
\end{definition}
\begin{remark}
    Every element of $A$ must go to a unique element of $B$
\end{remark}
\begin{example}
    $f : \mathbb{R} \rightarrow \mathbb{R}$ s.t. $f(x) = x^2$ \\ and a different function \\
    $f: \mathbb{R} \rightarrow \mathbb{R}_{\geq 0}$ s.t. $g(x) = x^2$
\end{example}
\begin{example}
    $A$ is a set, $p: A \rightarrow \mathcal{P}(A)$ where $p(x) = \{x\}$
\end{example}
\begin{definition}[Surjections]
    $f: A \rightarrow B$ is \textbf{onto} or \textbf{surjective} if for every $b \in B$, there exists an $a \in A$ s.t. $f(a) = b$.  That is: $$\forall b \in B\text{, } \exists a \in A \text{s.t.} f(a) = b$$
\end{definition}
\begin{example}
    Question: $A \subset B$. Can $f: A \rightarrow B$ be onto?\\
    Answer: When $A, B$ are finite, no, but 
\end{example}
\begin{definition}[Injections]
    $f: A \rightarrow B$ is \textbf{one-to-one} or a \textbf{injective} if for every $a_1, a_2 \in A$ $(f(a_1) = f(a_2) \rightarrow a_1 = a_2)$
\end{definition}
\begin{remark}[Bijections]
    Notice that our use of one-to-one is sometimes different than other uses, when it often referrs to a bijection, which is injective both ways, or injective and surjective. Notice that this implies bijections are invertible.
\end{remark}

\subsubsection{Cardinality}
\begin{definition}[Cardinality]
    The \textbf{cardinality} of $A$, denoted $|A|$, is the number of elements in the set
\end{definition}
\begin{definition}[finite and infinite sets]
    A set $A$ is \textbf{finite} if it has exactly $n$ elements for some non-negative integer $n$. $n$ is the cardinality of $A$
\end{definition}
\begin{proposition}
    If $A, B$ are finite, and $f: A\rightarrow B$ is onto, then $|A| \geq |B|$
\end{proposition}
\begin{example}
    If $|A| < |B|$, then it cannot be onto.  Proof by pigeonhole principle.
\end{example}
\noindent
\Line
\\
\subsection{9.17.2024}
\subsubsection{Cardinality2}
\begin{definition}[Cardinality of not necessarily finite sets]\\
    If $A, B$ are sets, they have the same cardinality if there is a bijection $f:A \rightarrow B$. \\
    If there is an injective function $f:A \rightarrow B$, then $|A| \leq |B|$.\\
    If $|A| \leq |B|$ but $|A| \neq |B|$ then we write $|A| < |B|$
    
\end{definition}

\begin{definition}[Countability]\\
    A set $A$ is countable if there is a bijection to $\mathbb{Z}_+$, or $|A| = |\mathbb{Z}_+$.  A function $f: \mathbb{Z}_+ \rightarrow A$ is called a \textbf{sequence}, written $a_1, a_2, a_3, \dots$, where $a_n = f(n)$.\\
    A sequence in which every element of $A$ occurs exactly once is called an \textbf{enumeration}.
\end{definition}

\begin{example}[Cardinality of $\mathcal{P}(\mathbb{Z})$]
    Is the power set $\mathcal{P}(\mathbb{Z})$ countable?  No, since we proved before that the cardinality of a power set is strictly greater than the cardinality of it's original set.
\end{example}

\begin{definition}[(0,1)]\\
    $(0,1) = \{0.d_1d_2d_3d_4\dots : d_i \in \{0, \dots , 9\} \text{ and $d_j$ are not all $0$} \}$ 
\end{definition}
\begin{theorem}[(0, 1) is uncountable]
    \textbf{Proof}: Assume $f: \mathbb{Z}_+ \rightarrow (0, 1)$.  We will show $f$ is not onto (codomain $\neq$ $(0, 1)$).  Consider the array: \\
    $\begin{array}{cc}
         f(1) &= 0.d_{11}d_{12}\dots   \\
         f(2) &= 0.d_{21}d_{22}\dots  \\
         f(3) &= 9.d_{31}d_{32}\dots 
    \end{array}$\\
    \\
    where $d_ij$ is the $j$th digit of $f(i)$. Look at the following example:\\
    \\
    $\begin{array}{cc}
         f(1) &= 0. 4362473  \\
         f(2) &= 0. 8765834  \\
         f(3) &= 0. 3498738  \\
         x    &= 0.356 \dots  
    \end{array}$\\
    \\
    We will construct an $x\in (0,1)$ such that $f(n) \neq x$ for all $n \in \mathbb{Z}_+$. Let $x = 0.x_1x_2x_3 \dots$ defined by $x_n \neq d_{nn}$\\
    Observe that for every $n$, $f(n) \neq x$ bas they differ in the $n$th digit, by construction.  Thus $f$ is not onto. \qed
\end{theorem}
\begin{remark}
    $|\mathbb{Z}_+| < |(0,1)|= |\mathcal{P}|$
\end{remark}

\subsubsection{"Prove or Disprove '$S$'"}
\begin{enumerate}
    \item Write down $S$ and $\neg S$
    \item Write down all definitions.
    \item Form a belief about $S$ or $\neg S$
    \item Use the steps above to try to write a proof \begin{enumerate}
        \item Success - backslash q e d
        \item Failure - articulate what you have learned and go back to $4$
    \end{enumerate}
\end{enumerate}
\noindent
\Line
\\
\section{Number Theory}
\subsection{9.19.2024}
\subsubsection{Division and Divisibility}
\begin{definition}[Divisibility]
    If $a \neq 0$ and $b$ are integers, then $a | b$ ($a$ divides $b$) if $\exists$ $k \in \mathbb{Z}$ s.t. $b=ka$
\end{definition}
\begin{example}
    $3|9$ because let $k=3$.  \\
    $3|0$ because let $k=0$\\
    $n|0$ by the same logic.
\end{example}
\begin{proposition}[Properties of Divisibility]
        Below are some properties of divisibiltiy\begin{enumerate}
        \item Transitivity
        \item If $a|b$ and $a|c$ then $a|b+c$
    \end{enumerate}
\end{proposition}
\begin{theorem}[Division Algorithm]
    If $a \in \mathbb{Z}$ and $d \in \mathbb{Z}_+$, then there exist unique integers $q, r$ s.t. $a=dq + r$ and $0 \leq r < d$
\end{theorem}
\begin{axiom}[Well-Ordering Principle]
    Every nonempty subset of $\mathbb{Z}_{\geq0}$ contains a least element.\\
    $\forall S \subseteq \mathbb{Z}_{\geq 0}\text{, } (S \neq \emptyset \rightarrow \exists y \in S\text{ s.t }( \forall x \in S \text{, } x > y))$
\end{axiom}
\subsubsection{Modular Arithmetic}
\begin{example}
    Time is $n\mod 12$,\\
    Days are $m\mod 7$
\end{example}
\begin{definition}
    If $a, b \in \mathbb{Z}$ and $m \in \mathbb{Z}_+$, then $a$ is congruent to $b \mod m$, denoted $a \equiv b \mod m$ if $a \mod m = b \mod m$ or equivalently, $m | b-a$
\end{definition}
\begin{proposition}
    Notice that these properties are similar to the divisibility properties
    \begin{enumerate}
        \item If $a \equiv b \mod m$ and $b \equiv c \mod m$, then $a \equiv c \mod m$
        \item If $a \equiv b \mod m$ and $c \in \mathbb{Z}$ then $ca \equiv cb \mod m$
        \item If $a \equiv b \mod m$ and $c \equiv d \mod m$ then \begin{enumerate}
            \item $a+c \equiv b+d \mod m$
            \item $ac \equiv bd \mod m$
        \end{enumerate}
    \end{enumerate}
\end{proposition}

\subsubsection{Representations of Numbers}
In decimal, $d_k, d_{k-1}, \dots , d_1 d_0$ means $d_010^0 + d_110^1 + \dots + d_k10^k$\\
\begin{fact}[base $b$ representation]
    If $b \in \mathbb{Z}_+$, every $a \in \mathbb{Z}_{\geq 0}$ can be written uniquelly as a sum of powers of $b$, ex. there are unique $a_0, a_1,\dots , a_k$ s.t. $a = a_1b^0 + a_1b^1 + \dots + a_kb^k$.  This is called the base b representation of $a$, denoted $a = (a_ka_{k-1} \dots a_0)_b$
\end{fact}
\noindent
\Line
\\
\subsection{9.24.2024}
\subsubsection{Primes}
\begin{definition}
    An integer $n>1$ is \vocab{prime} is it has no divisors other than $1$ and itself. \[ n \text{ is prime} \leftrightarrow \forall a( a|n \rightarrow a = 1 \text{ or } a =n\]
    A number that is not prime is composite.  i.e., there exists $a, b > 1$ such that $n=ab$
\end{definition}
We are now going to prove that there are $\infty$ primes.
\begin{lemma}
    If $c>1$ is composite, there exists a prime $p<c$ such that $p | c$.
\end{lemma}
\begin{proof}
    Assume $c > 1$ is composite. Let $S = \{a \in \mathbb{N} : a|c \wedge a > 1\}$ (the set of all nontrivial divisors). We know this is non-empty because $c$ is composite. So we can choose a least element $p$ (by the well ordering principle). Assume for contradiction that $p$ is composite. By definition, there exists $b>1$ such that $b|p$.  But $b|p$ and $p|c$ implies $b|c$, thus $b$ is in $S$.  But $b > p$ because we chose a smallest element of $S$.  Then we have a contradiction.
\end{proof}

\begin{theorem}
    There are infinitely many primes
\end{theorem}
\begin{proof}
    Assume for contradiction there are finitely many primes $p_1, p_2, \dots p_n$.  Consider $q = (\prod_{i \in I}p_i) + 1$.  Since $q$ is not prime (it is bigger than all the primes), it must be composite.  By lemma $3.2.10$, we can choose some prime $p_i$ such that $p_i|q$.  But $p_i$ also divides $q-1$.  This is impossible, thus we have a contradiction.
\end{proof}
\begin{theorem}[The Fundamental Theorem of Arithmetic]
    Every integer $n>1$ can be written uniquely as a product of primes arranged in nondecreasing order. (By making it a monotonic sequence (ordered) we have made it unique)
\end{theorem}

\subsubsection{GCD}
\begin{definition}[Greatest Common Divisor]
    If $0< a, b \in \mathbb{Z}$, the greatest common divisor of $a$ and $b$, denoted $\gcd(a, b)$ is the largest $d \in \mathbb{N}$ such that $d|a$ and $d|b$.
\end{definition}

\textbf{Fact}: If $a > b > 1$ and $a = bq + r$,  $0 \leq r < b$, then $\gcd(a, b) = \gcd(b, r)$


\subsubsection{Euclidean Algorithm}
\vocab{Euclidean Algorithm}: Repeatedly apply the key observation until $r=0$ - This always occurs as $r<b$ always.

\begin{lemma}
    If $a>b>1$, and $a = bq + r$, $0 \leq r < b$, then for all $d \in \mathbb{Z}_+$, $(d|a \text{ and } d|b \rightarrow d|b \wedge d|r)$. 
\end{lemma}
\begin{proof}
    \rightarrow direction\\
    Assume $a>b>1$, $a = bq + r$, $0\leq r < b$.  Assume $d \in \mathbb{N}$ with $d|a$ and $d|b$.  Observe that $d|bq$, so $d|a-bq$.  Thus $d|r$.  \\
    The left direction is similar.
\end{proof}
\begin{theorem}[Bézouts Lemma]
If $a, b\in \mathbb{Z}$, not both $0$, then there exists some $s, t \in mathbb{Z}$ (can be negative) such that $\gcd(a,b) = sa + tb$     (professor accidentally called this Bézouts Theorem)
\end{theorem}
\begin{proof}
    Follows by substituting remainders in the euclidean algorithm
\end{proof}
We will try another way.
\begin{proof}
    Consider $S = \{sa + tb: s, t \in \mathbb{Z} \wedge sa = tb \geq 1\} \subseteq \mathbb{N}$.  Observe that $S \neq \emptyset$ since $a^2 + b^2 \in S$.  Then we can choose a least element $g$ (by the well ordering principle), such that $g = sa + tb$.  We will show that $g = \gcd(a, b)$ 
    \begin{proposition} $g|a$ and $g|b$
        Assume towards contradiction the $g \nmid a$. Choose r such that $0<r<g$ and $a = gq + r$.  Observe $r = a - gq = a - (sa + tb) q = (1-q) a + (-tq) b \in S$ (since $r>0$).  But this contradicts the minimality of $g$  \qed
    \end{proposition}
    \begin{proposition}[If for $d\in \mathbb{N}$, $d|a$ and $d|b$, then $d|g$]
        This proof is left as an excercise for the reader
    \end{proposition}
\end{proof}

\begin{corollary}[Strong Bézout]
    If $a, b \in \mathbb{Z}$ not both $0$, then $\gcd(a, b) = \min\{sa + tb : s, t \in \mathbb{Z}, sa + tb \geq 1\}$
\end{corollary}
\begin{remark}[For the exam]
    \begin{enumerate}
        \item Proofs aren't unique. 
        \item Complete sentences, clearly specifying final proof (can use existential qualifiers)
        \item Use definitions (know them)
    \end{enumerate}
\end{remark}
\noindent
\Line
\\
\section{Induction}
\subsection{10.8.2024}
\subsubsection{Induction}
\vocab{Induction} is a new \textbf{Inference Rule} for proving statements of the form: $\forall n \in \mathbb{N} P(n)$
\begin{example}
    $\forall n \in \mathbb{N} (n! < 2^n)$.\\
\end{example}
\begin{definition}[Principle of Mathematical Induction]
    Let $P(n)$ be a predicate.  Induction tells us that from \begin{enumerate}
        \item A basis step $P(1)$
        \item An inductive step $\forall k \in \mathbb{N} (P(k) \rightarrow P(k+1))$
    \end{enumerate}
    We get: $\forall n\in \mathbb{N} P(n)$
\end{definition}
\begin{proposition}
    $\forall n \in \mathbb{N} (\sum_{i=1}^{n} i = \frac{n(n+1)}{2})$
\end{proposition}
\begin{proof}
    We proceed by induction. \\
    Basis step: For $n=1$ we have $1 = \frac{1*2}{2} = 1$. \\
    Inductive step: Suppose $\sum_{i=1}^n i= \frac{n(n+1)}{2}$.  Then $\sum_{i=1}^{n+1} i = \frac{n(n+1)}{2} + n + 1 = \frac{n(n+1) + 2n + 2}{2} = \frac{(n+2)(n+1)}{2}$.\\
    Then for all $n$, the identity holds.
\end{proof}

\begin{remark}
    The validity of induction follows from the well-ordering principle.
\end{remark}
Let $S_k = \sum_{i=1}^{k}(2i+1)$ (the sum of odd numbers to $k$
\begin{proposition}
    $\forall n \in \mathbb{N}~ (\exists m \in \mathbb{N} | S_n = n^2)$
\end{proposition}
\begin{proof}
    We proceed by induction:\\
    Basis step: For $n=1$, there exists $m=1$ s.t. $S_1 = 1 = 1^2$\\
    Inductive Step: Assume $k \in \mathbb{N}$. Assume $P(k)$. We will show $P(k+1)$. By $P(k)$, we know that $S_k = k^2$. Observe that $S_{k+1} = \sum_{i=1}^{k+1}(2i+1)= \sum_{i=1}^{k+1}(2i+1) + 2(k+1) - 1 = \sum_{i=1}^{k+1} = k^2 + 2k + 1 = (k+1)^2$, establishing $P(k+1)$, as desired 
\end{proof}
\begin{remark}
    Sometimes, it is easier to prove a stronger statement by induction ex. its more difficult to prove for some arbitrary $m$ rather that $m = k$
\end{remark}
Strong induction next time due to technical difficulties. \\
\noindent
\Line
\\
\subsection{10.10.2024}
\subsubsection{Tilings}
\begin{proposition}
    For every $n \in \mathbb{N}$, for every $2^n \times 2^n$ chessboard with an arbitrary square removed, the board can be perfectly tiled with  triominos.
\end{proposition}

\begin{proof}
    We proceed by induction:
    \begin{itemize}
        \item Basis step: If $n=1$, the board must be one of 4 cases, each of which can be tiled by a single triomino.
        \item Induction Step: Suppose we can tile a $2^k\times 2^k$ board with one piece removed. Then we can tile $3$ other boards with one extra tile, which we can have in any place we want.  Then we can organize four of the $2^k\times2^k$ boards together so that there is a missing triomino in the center, which we can fill in with another triomino.
    \end{itemize}
\end{proof}
\subsubsection{Strong Induction + Recursive Definition}
\begin{definition}[Strong Induction]
    Suppose you know $P(1)$.  Then $\forall k \geq 1$, $P(1) \wedge P(2) \wedge \dots \wedge P(k) \rightarrow P(k+1)$.
\end{definition}
\noindent
We are looking for a way to define $f:\mathbb{Z}_+ \rightarrow \mathbb{Z}$ or $f:\mathbb{Z}_{\geq 0} \rightarrow \mathbb{Z}$\\
So far we have three ways: \begin{enumerate}
    \item Explicit formula
    \item $a_1, a_2, a_3, \dots $ and editing
\end{enumerate}
\textbf{New Way}: to define $f: \mathbb{Z}_+ \rightarrow A$:\begin{itemize}
    \item Basis Step: For some $b \geq 1$, define $f(1), f(2), \dots, f(b)$. 
    \item Recursive Step: For every $k \geq b$, define $f(k + 1)$ in terms of $f(1), f(2), \dots, f(k)$.
\end{itemize}
\begin{example}
    Fibonacci
\end{example}
\begin{example}
    $f: \mathbb{Z}_+ \rightarrow \mathbb{R}$
    \begin{itemize}
        \item Base: $f(1) = 1$
        \item Recursive $f(k+1) = \sqrt{1+f(k)}$
    \end{itemize}
\end{example}
\begin{definition}[Golden Ratio]
    $\frac{1+\sqrt{5}}{2}$
\end{definition}
\begin{theorem}
    For $n\geq 2$, $f(n) \geq \phi^{n-1}$
\end{theorem}
\begin{proof}
    We proceed by \textbf{STRONG} induction\begin{itemize}
        \item Base Case(s): For $n=2$, $f(2) = 2 \geq \phi^1$.  For $n = 3$, $f(3) = 3 \geq \phi^2$
        \item Inductive Step: Assume $k \geq 3$. Assume $P(2), P(3), \dots, P(k)$.  We will show $P(k+1)$.\\
        Observe that $f(k+1) = f(k) + f(k-1) \geq \phi^{k-1} + \phi^{k-2} = \phi^k$
    \end{itemize}
\end{proof}
\noindent
\Line
\\
\section{Graph Theory}
\subsection{10.15.2024}
\subsubsection{Graphs}
\begin{remark}
    A \vocab{graph} is a mathematical abstraction of \vocab{pairwise} relationships.
\end{remark}
\begin{definition}
    A \vocab{simple graph} $G = (V, E)$ is a pair of sets: \\
        $V$, the set of vertices\\
        $E$, the set of edges\\
        Such that $E$ is a set of unordered pairs of elements of $V$ i.s., $E \subseteq\{S \subseteq V: |S| = 2\}$
\end{definition}
\begin{example}
    $V=\{1, 2, 3\}$, $E = \{\{1, 2\}, \{2, 3\}, \{1, 3\}\}$
    % https://q.uiver.app/#q=WzAsMyxbMCwxLCIyIl0sWzEsMCwiMSJdLFsyLDEsIjMiXSxbMSwwLCIiLDAseyJzdHlsZSI6eyJoZWFkIjp7Im5hbWUiOiJub25lIn19fV0sWzAsMiwiIiwwLHsic3R5bGUiOnsiaGVhZCI6eyJuYW1lIjoibm9uZSJ9fX1dLFsyLDEsIiIsMCx7InN0eWxlIjp7ImhlYWQiOnsibmFtZSI6Im5vbmUifX19XV0=
\[\begin{tikzcd}
	& 1 \\
	2 && 3
	\arrow[no head, from=1-2, to=2-1]
	\arrow[no head, from=2-1, to=2-3]
	\arrow[no head, from=2-3, to=1-2]
\end{tikzcd}\]
\end{example}

\begin{definition}
    A \vocab{multigraph} $G = (V, E)$ is a pair of sets: \\
        $V$, the set of vertices\\
        $E$, the multiset of edges\\
        Such that $E$ is a set of unordered pairs of elements of $V$ i.s., $E \subseteq\{S \subseteq V: |S| = 2\}$
\end{definition}
\begin{remark}
    \begin{itemize}
        \item We will only be working with undirected graphs
        \item $V$ will be finite
        \item If $E$ has repetitions, $G$ is a multigraph, otherwise it is a simple graph
    \end{itemize}
\end{remark}
\begin{motivation}
\textbf{Motivation}:
    \begin{enumerate}
        \item Internet: $V = \{\text{servers}\}$, $E = \{xy: x \text{ is connected to $y$ by a wire}\}$
        \item Social Network: $V\{\text{people}\}$, $E = \{\text{a relationship between two people}\}$
    \end{enumerate}
\end{motivation}

\subsubsection{Degree and Handshaking}
\begin{terminology}
    \textbf{Terminology}: Given $G=(V, E)$, if $e = xy \in E$, then $x$ is \vocab{adjacent} to $y$ in $G$.  $e$ is \vocab{incident} with $x$ or $y$.  $x,y$ are \vocab{endpoints} of $e$.
\end{terminology}
\begin{definition}
    The \vocab{degree} of a vertex is the number of edges incident with it.  $\text{deg}(v) = |\{e \in E : e \text{ is incident with } v\}|$
\end{definition}
\begin{theorem}[Handshaking]
    If $G = (V, E)$ is a graph, $$\sum_{v \in V} \text{deg}(v) = 2|E|$$
\end{theorem}
\begin{proof}
    Assume $G = (V, E)$ is a graph. Consider $I = \{(e, v) : e \in E, v \in V, e \text{ is incident with }v\}$\\
    We will count the number of incidences $|I|$ in two ways \begin{enumerate}
        \item Each edge $e \in E$ participates in exactly two indices. No incidence participates in more than one edge. Thus, $|I| = 2|E|$
        \item Each vertex $v \in V $ participates in exactly $\text{deg}(v)$ incidences.  And no incidence participates in more than one vertex.  Thus $|I| = \sum_{v \in V} \text{deg}(v) = 2|E|$.
    \end{enumerate}
\end{proof}
\begin{corollary}
    In any graph, there are an even number of odd degree vertices.
\end{corollary}
\begin{proof}
    Suppose $G$ has $n_1$ even degree vertices, and $n_2$ odd degree vertices.  Observe $$\sum_{v \in V } \text{deg}(V) = \sum_{v \in V  : \text{ v is odd}} \text{deg}(v) + \sum_{v \in V : \text{ v is even}} \text{deg}(v) \equiv 0 + n_2 (\mod 2) \equiv 2|E| (\mod 2) \equiv 0 (\mod 2)$$  
\end{proof}

\subsubsection{Ramsey Theory}
\begin{theorem}
    In any group of $6$ people, there are $3$ acquaintances or $3$ strangers.
\end{theorem}
\begin{proof}
    Consider the graph $G = (V, E)$\\
    $V = \{1, 2, 3, 4, 5, 6\}$, $E = \{xy : x \text{ and } y \text{ are acquaintances} $.\\
    Choose an arbitrary vertex $x$. \\
    Case 1: deg$(x) \leq 2$: Choose $a, b, c \in V$ such that $xa, xb, xc \notin E$.  Observe that either $ab, bc, ca$ are all edges, in which case we are done, \textbf{or} without loss of generality, $bc \notin E$, which implies $xa, xb, bc \notin E$, so $\{x, b, c\}$ are strangers, as desired\\
    Case 2: Homework
\end{proof}
\begin{theorem}
    For all groups of $18 $ there exists $4$ who are acquaintances or strangers 
\end{theorem}
\begin{theorem}
    For all $k \geq 2$, there exists $N$ such that for all groups of $\geq N$, people there exists subgroups of $k$ strangers or acquaintances
\end{theorem}
\subsubsection{Connected Components}
\begin{definition}
    A \vocab{path} of length $k$ in a graph $G = (V, E)$ is an alternating sequence of vertices $x_i \in V$ and edges $e_i \in E: x_0, e_1, x_2, e_2, \cdots, e_k, x_k$ such that for all $i = 1, \cdots, k$, $e_i = \{x_{i-1}, x_i\}$.\\
    A path in which no vertex is repealed is called \vocab{simple}.
\end{definition}
\begin{definition}
    A graph $G = (V, E)$ is \vocab{connected} if for all $x, y \in V$, there is a path in $G$ between $x$ and $y$.
\end{definition}
\begin{remark}
    If there is a path from $x$ to $y$, then there is a path from $y$ to $x$, by reversing the sequence.\\
    If there is a path from $x$ to $y$, and from $y$ to $z$, then there is a path from $x $ to $z$. 
\end{remark}
\begin{example}[Cycle]
    $V = \{0, \dots, n-1\}$\\
    $E = \{xy : x-1 \equiv 1 (\mod n)\}$
\end{example}
\begin{example}[Complete]
    $V = \{1, \dots, n\}$\\
    $E = \{S: S \subseteq V, |S| = 2\}$
\end{example}
\begin{example}[Independent Set]
    $V = \{1, 2, \dots n\}$\\
    $E = \emptyset$
\end{example}
\begin{definition}[Subgraph]
    A graph $H = (W, F)$ is a \vocab{subgraph} of $G = (V, E)$ if $W \subseteq V$ and $F \subseteq E$.
\end{definition}
\begin{example}
    Independent $\subseteq$ Cycle $\subseteq$ Complete (on $\{1, \dots, n\}$)
\end{example}
\begin{definition}
    A \vocab{connected component} of $G = (V, E)$ is a subgraph $H \subseteq G$ which is \begin{enumerate}
        \item Connected
        \item Maximal, i.e., for every subgraph $H' \subseteq G$ such that $H \subseteq H'$, $H'$ is not connected
    \end{enumerate}
\end{definition}
\begin{theorem}
    Every graph is a disjoint union of its connected components.  (Proved in HW using strong induction)
\end{theorem}

\noindent
\Line
\\
\subsection{10.17.2024}
\subsubsection{Connected Components}
\begin{definition}
    A graph $H=(F, W)$ is a connected component of $G=(V, E)$ if it is a maximal connected subgraph of $G$. i.e., $H \subseteq G$, $H$ is connected, $\forall~H' \subseteq G, ~(H' \nequiv H \rightarrow H \text{ is not connected})$
\end{definition}
\begin{theorem}
    Every graph is a disjoint union of its connected components.
\end{theorem}
\begin{lemma}
    If $G=(V, E)$ is a nonempty graph, then it has at least $1$ connected component. 
\end{lemma}
\begin{proof}
    Choose a vertex $x \in V$. Define the set $W = \{y \in V : \text{ there is a path from } x \text{ to } y \text{ in } G \cup \{x\}\}$.  Consider the subgraph $H = (W, F)$ where $F= \{xy \in E : x, y \in W\}$ (This is called an \vocab{induced subgraph}).  \\
    Let $z,y$ be distinct vertices in $W$.  Then there exists a path $xz \in W$ and a path $yx \in W$.  By transitivity, we can concatenate these paths, thus there exists a path $yz: y \rightarrow z \in G$.  Observe that the concatenation is a path in $H$, so $H$ is connected.\\
    To see that $H$ is maximal, assume $H \subset H'$.  This implies that there is some vertex $y \in H'$ such that $y \notin W$.  By construction of $W$, there is no path from $y'$ to $x$ in $G$, so there is no path from $y'$ to $x$ in $H'$, so $H'$ is connected.
\end{proof}
\begin{proof}[5.23]
    Use strong induction.
\end{proof}
\subsubsection{k-coloring}
\begin{definition}
    A \vocab{k-coloring} of $G=(V, E)$ is a function $F: V \rightarrow \{1, 2, \dots, k\}$ such that for all $xy \in E$, $(f(x) \noteq f(y))$
\end{definition}
\begin{example}
    The complete graph with $3$ vertices is $3$-colorable
\end{example}
The smallest $k$ such that $G$ is k-colorable is called its \vocab{chromatic number } denoted $\chi(G)$.

\begin{theorem}
    IF $G$ is a graph, with maximum degree $D$ then $\chi(G) \leq D+1$
\end{theorem}
\begin{remark}
    For all $i \leq n$, $S_i=\{x \in V: f(x) = i\}$ is an independent set.
\end{remark}
\begin{proof}
    By induction.  Assume $D \geq 0$. Let $P(n)$ be the statement: "For all graphs $G$ with $\leq n$ vertices, if max deg$(G) \leq D$, then $\chi(G) \leq D+1$."  \begin{itemize}
        \item Base Case: Every graph with $1$ vertex is $1$-colorable, so it must also be $2$-colorable.
        \item Inductive Step: Assume $k\in \NN$. Assume $P(k)$.  We will show $P(k+1)$. Assume $G$ has $k+1$ vertices and maximum degree $D$. Choose vertex $x \in V$.\\
        Let $y_1, \dots, y_m$ be the vertices adjacent to $x \in G$.  \\
        Let $H=(W, F)$ be the subgraph obtained by deleting $x: W = V / \{x\}$, $F = \{yz \in E: y, z \in W\}$.  Since $H$ has maximum degree $\leq D$ and $k$ vertices, $P(k)$ implies that there is a $D+1$-coloring $f': W \to \{1, \dots, D+1\}$ of H. \\
        Observe that $\{1, \dots, D+1\} - \{f(y_1), \dots, f(y_k)\} \neq \emptyset$ since $m \leq D$. Let $j$ be any color in the set.\\
        Define $f: V \rightarrow \{1, \dots, D+1\}$ be \begin{cases}
            f(y) = f'(y) \text{ for } y \neq x\\
            f(x) = j
        \end{cases}
        $f$ is a valid coloring of $H$ and also of the edges $xy_1, xy_2, \dots, xy_m \in G$ by construction, so $f$ is a valid coloring of $G$ and $G$ is $D+1$ colorable, as desired.
    \end{itemize}
\end{proof}
\subsubsection{2-colorings}
\begin{definition}
    A path $x_0, e_1, x_1, \dots, e_k, x_k$ is called a \vocab{circuit} if $x_0 = x_k$
\end{definition}
\begin{remark}
    For coloring, graphs are simple.
\end{remark}
\begin{theorem}
    A graph $G$ is $2$-colorable IFF it does not contain a circuit of odd length. 
\end{theorem}
\begin{proof}
    ($\rightarrow$) Assume $G$ is $2$-colorable.  Choose a $2$-coloring $f: V \rightarrow \{1, 2\}$.  Assume $G$ contains a circuit $C = x_0, x_1, \dots, x_k$ with $x_k = x_0$. Consider the sequence $f(x_0), f(x_1), \dots, f(x_k)$.  Observe that $f(x_i) \neq f(x_{i+1}$ for all $i \leq k-1$, so $f(x_i) = f(x_0)$ for all even $i$ and $f(x_i) \neq f(x_0)$ for all odd $i$, i.e., the colors alternate as $i = 0, \dots, k$.  In particular, $f(x_k) \neq f(x_0)$, a contradiction since $x_k = x_0$. \qed 
\end{proof}
\noindent
\Line
\\
\subsection{10.24.2024}
\subsubsection{Leonhard Euler}\footnote{len-hard yule-her}
\begin{example}
    $_{\textsc{The}}$ $\textbf{S}^\textbf{ev}_\textbf{en} \textbf{Br}^\textbf{id}_\textbf{ges}$ $_{\textsc{Of}}$ \textbf{Könisburg}
\end{example}
\begin{definition}
    An \vocab{Eulerian circuit} in a graph $G= (V, E)$ is a circuit which traverses every edge exactly once.
\end{definition}
\begin{theorem}
    If a graph $G=(V, E)$ with $|V|\geq 2$ has an eulerian circuit, then the degree of every vertex $v\inV$ has to be even.
\end{theorem}
\begin{proof}
    Assume $G=(V, E)$ is connected and $|V| \geq 2$.  Let $C = x_0, e_1, \dots, e_m, x_0$  be an eulerian circuit of $G$. Assume $v \neq x_0$ is a vertex of $G$.  Suppose $C$ visits $V$ exactly $k$ times. Observe that in each visit, $C$ traverses exactly $2$ edges incident with $V$. Since $C$ is eulerian, these pairs of edges must be disjoint, and every edge incident with $v$ appears in a pair.  Thus the edges incident with $v$ can be partitioned into $k$ pairs, so deg$(v) = 2k$, as desired.  By handshaking, $\sum \text{deg}(v) = 2|E|$, so $x_0 $ is even, completing the proof.
\end{proof}
\begin{theorem}
    If a connected graph $G=(V, E)$ has deg$(v)$ even for all $v \in V$ and $|V| \geq 2$ then $G$ has an eulerian circuit.
\end{theorem}
\begin{lemma}
    If $G=(V, E)$ is a graph with deg$(V) \geq 2$, for all $v \in V$, then $G$ contains a cycle.
\end{lemma}
\begin{proof}
    We will prove by contrapositive. Assume $G = (V, E)$ is acyclic. We will show $G$ has a vertex $v$ with deg$(v) \geq 2$.  Let $G_1, \dots, G_k$ be the connected components of $G$. Observe that each $G$ is connected and acyclic since $G_i \subseteq G$ and $G$ is acyclic, so $G_i$ is a tree for $i=1, \dots, k$. If some $G_i$ has at least $2$ vertices, it must have a leaf $l$, with deg$(l)=1$.  But then $l$ has degree $1$ in $G$ as well, since $G_i$ is a connected component. If all $G_i$ have exactly one vertex, then we have an independent set and thus deg$(V)=0$
\end{proof}
\begin{proof} \textit{ of Theorem 5.35}: Proceed by induction on the number of edges $m$.\begin{itemize}
    \item Our induction hypothesis is: Let $P(n) = $ "If $G$ has $m $ edges, $\geq 2$ vertices, is connected, and has all even degrees, then $G$ has an eulerian circuit."  We will show $P(m)$ for all $m \geq 2$.
    \item Base Case: The only connected (multi) graphs with $2$ edges and all even degrees (and no self loops) has an eulerian circuit. 
    \item Inductive Step: Assume $m \geq 2$, $P(2), P(3), \dots, P(m)$. Assume $G = (V, E)$ is a connected graph with $m+1$ edges, all even degrees, at least $2$ vertices.  \\
    By the Lemma, $G$ contians a cyc;e $C = (V_c, E_c)$. If $C = G$, then traversing $C$ yields an eulerian circuit of $G$.\\
    If $C \neq G$, let $H = G-C = (V, E-E_c)$ be the graph obtained by removing the edges of $C$ from $G$. \\
    Let $H_1, \dots, H_k$ be the connected components of $H$ with at least $2$ vertices.  Observes that for all $i = 1, \dots, k$, \begin{enumerate}
        \item $H_i$ is connected and has $\geq 2$ vertices. 
        \item Each $H_i$ has at most $|E| - |E_c| \leq m+1 -2 \leq m-1$
        \item The degree of every vertex $v \in H_i$ is deg$_{H_i}(v) = \text{deg}_G(v) - \text{deg}_C(v)$.
    \end{enumerate}
    Since deg$_G(v)$ is even and deg$_C(v) \in \{0, 2\}$, deg$_{H_i}(v)$ is even.\\
    Claim: For every $i=1, \dots, k$, there exists a vertex $s_i \in H_i$ such that $C$ visits $s_i$ \\
    \text{HW}\\
    By induction, each $H_i$ has an eulerian circuit $C_i$ which WLOG starts and ends at $s_i$.  In a connected graph, if there is an eulerian circuit, then for all $v \in V$ there is one starting at $v$.\\
    Let $C'$ be equal to $C$ with the first occurence of $s_i$ in $C$ replaced by $C_i$, for $i=1, \dots, k$\\
    Observe that \begin{enumerate}
        \item $C'$ is a circuit
        \item $C'$ traverses every edge of $C \cup H_1 \cup H_2 \cup \dots \cup H_k = G$ exactly, once, as desired.
    \end{enumerate}
\end{itemize}
\end{proof}
\begin{remark}
    \begin{itemize}
        \item Naming objects is important
        \item Proofs are not unique
        \item Many proofs give algorithms.
    \end{itemize}
\end{remark}
\noindent
\Line
\\
\section{Counting}
\subsection{10.29.2024}
\subsubsection{Prototypical Examples}
\textbf{Goal}: Count the number of objects satisfying a given property. i.e., find the cardinality of $S= \{x : P(x)\}$. 
\begin{example}
    Bit strings of length $10$, $S = \{(b_1, \dots, b_{10}) : b_i \in \{0, 1\}\}$
\end{example}
\begin{example}
    Bit strings of length $5$ ending in $00$ or beginning with $1$. $S = \{(b_1, \dots, b_{5}) : b_i \in \{0, 1\}, b_4 = b_5 = 0 \vee b_1 = 1\}$
\end{example}
\begin{example}
    Number of rankings of \{Cal, Stanford, UCLA, USC\}.
\end{example}
\begin{example}
    Ordered sequences of $5$ distinct cards from a deck of $52$. $\{(c_1, c_2, \dots, c_5): c_i \in \{\text{cards}\}, c_i \text{distinct}\}$
\end{example}
\begin{example}
    Unordered sets of $5$ distinct cards from a deck of 52
     Ordered sequences of $5$ distinct cards from a deck of $52$. $\{\{c_1, c_2, \dots, c_5\}: c_i \in \{\text{cards}\}, c_i \text{distinct}\}$
\end{example}
\begin{example}
    Simple graphs with vertex set $V = \{1, 2, \dots, n \}$
\end{example}


\subsubsection{Principles of Counting}
\begin{enumerate}
    \item If $f: A \to B$ is a bijection, then $|A| = |B|$.
    \item $|A \times B| = |A| |B| \xrightarrow[\text{induction}]{} |A_1 \times \dots \times A_k = |A_1| \times |A_2| \times \dots \times |A_k|$
    \item $|A \cup B| = |A| + |B| - |A \cap B|$ This is called the principle of inclusion exclusion \vocab{PIE}
    \item Suppose an object from a set $S$ is uniquely specified by a sequence of $k$
     choices $C_1, C_2, \dots, C_k$ and \begin{enumerate}
         \item The number of ways to make $C_1 = n_1$  
         \item Given $C_1$, number of ways to make $C_2 = n_2$
         \item Given $C_1, C_2, \dots, C_{k-1}$ Number $C_k = n_k$
     \end{enumerate}
     Then $|S| = n_1 n_2 \dots n_k = $ the number of ways to make $(C_1, C_2, \dots, C_k)$. (\vocab{Product Rule})
\end{enumerate}
\textbf{Example 6.1:}\\ \noindent
Observe: $S = \{0, 1\} \times \dots \times \{0, 1\} 10$ times $  =\{0, 1\}^{10}$\\
$2^{10}  = 1024$
\\
\\
\newline \noindent
\textbf{Example 6.2}:\\ \noindent
Observe: $S = \{A \cup B\}$, $A = \{\underline{b}: b_4 = b_5 = 0\}, B = \{\underline{b} : b_1 = 1\}$
PIE: $|S| = |A| + |B| - |A \cap B|$\\ \noindent
$f: A \to \{0, 1\}^3$ is a bijection, so $f(\underline{b}) = (b_1, b_2, b_3)$. \\ \noindent
$|A| = |\{0, 1\}|^3 = 2^3 = 8$.\\
Similarly, we can show that $|B| = 2^4 = 16$.\\
Then, we see that $|A \cap B| = 2^2 = 4$.  Thus we have $$|S| = 8 + 16 - 4 = 20$$
\\
\\
\noindent
\textbf{Example 6.3}: \\ \noindent
Product Rule:\\
Observe: We want to decompose our "big" choice into a sequence of small choices. 
Process: \begin{itemize}
    \item Choose school number one
    \item Choose school number two given school number one
    \item Choose school number three given schools two and one
    \item Given the first 3, choose our fourth school.
\end{itemize}
Our first choice has $4$ options, our second choice has only $3$ options our third one $2$, and our last one we only have $1$ school.  Then we have: $$4*3*2*1 = 4!$$  \\
We can consider a decision tree of our options
\begin{remark}
    Each $s \in S$ is uniquely specified by a sequence of choices i.e., there is a bijection from the set of orderings to the ways of ordering it 
\end{remark}
\\
\begin{definition}
    An ordering of $n$ distinct objects is called a \vocab{permutation}. 
\end{definition}
The number of permutations of $n$ distinct objects is $n!$, proven by the product rule.
\\
\noindent
\textbf{Example 6.4}: \\ \noindent
Observe: By the product rule, first let us describe our process. \begin{itemize}
    \item Choose $c_1$
    \item Given $c_1$, choose $c_2$
    \item Given $c_1, c_2$, choose $c_3$
    \item et cetera
\end{itemize}
Next, we can see that $|S| = \frac{52!}{47!}$
\begin{definition}
    An ordered sequence of $r$ distinct objects chosen from $n$ distinct objects is called an $r$-permutation.  The number is $\frac{n!}{(n-r)!}$
\end{definition}
\\
\\
\noindent
\textbf{Example 6.5}: \\ \noindent
Observe: We will proceed by division rule: Attempt: Process: \begin{itemize}
    \item Choose a card $c_1$
    \item Choose $c_2 \neq c_1$
    \item et cetera
\end{itemize}
The problem with this is that it doesn't uniquely specify an unordered set of cards
\begin{definition}
    $f: A \to B$ is $m$-to-$1$ if it is onto and $\forall~ b \in B$, $|f^{-1}(\{b\})| = m$, 
\end{definition}
Notice that our mapping from choices to unordered hands is an $m$-to-$1$ function.  So we have the same thing as before but we are dividing by the number of orderings of our sequence by $5!$.  So we have $52\choose 5$ or $\frac{52!}{47!5!}$
\\
\\
\subsection{10.31.2024}
\subsubsection{Binomial Theorem}
\begin{theorem}
    If $n \geq 1$, then $$(x+y)^n = \Sigma_0^n {n\choose k} x^ky^{n-k}$$
\end{theorem}
\begin{proof}
    Observe that the expansion of $(x+y)^n$ consists of terms corresponding to $xy$-strings of length $n$, since each term is defined by choosing a veriable $x$ or $y$ from each paranthesized factor of $(x+y) \dots (x+y)$.  Grouping monomials, the coefficient of $x^ky^{n-k}$ is the number of $xy$-strings of length $n$ with exactly $k$ $x$'s, which is equal to the number of $k$-subsets of $\{1, \dots, n\}$, which is ${n \choose k}$
\end{proof}
\subsubsection{Combinatorial Identities}


\subsubsection{Permutations and Combinations with Repitition}
stars and bars or something

\newline
\noindent
\Line
\\
\subsection{11.5.2024}
\subsubsection{Ball and Urns}
no stars and bars are here
\subsubsection{Recurrence Relations}
\newline
\noindent
\Line
\\
\section{Probability}
\subsection{11.14.2024}
\subsubsection{Probability}
joke: what does Math stand for?
\newline
\\
\\
\\
\\
\noindent
A: Math Ath Th H
\\
Axioms of Classical Probability
\begin{enumerate}
    \item An \vocab{experiment} is a well-defined procedure with a set of outcomes.  An outcome is a complete specification of (all the relevant details of) an experiment.
    \item The set of possible outcomes of an experiment is called a \vocab{sample space} $S$. 
    \item An \vocab{Event} is a subset of the sample space $E \subseteq S$
    \item Given that, \begin{enumerate}
        \item $S$ is finite
        \item All outcomes in $S$ are equally likely
    \end{enumerate}
    the probability of an event $E$ denoted $\mathbb{P}(E)$ is $\PP(E) = \frac{|E|}{|S|}$
\end{enumerate}

What does $\PP(E)$ mean? \begin{itemize}
    \item Frequentist Interpretation: If you repeat the experiment many times, the outcome will lie in E $\approx \PP(E)$ fraction of the time.
    \item
\end{itemize}
\newline
\noindent
\Line
\\
\subsection{12.3.2024}
\subsubsection{Coupon Collector}
\begin{example}
    Roll a fair die until I see two distinct numbers; i.e., $(1, 1, 1, 1, 1, 1, 4)$. What is the expected number of rolls? \\
    \noindent
    We can view this experiment in multiple different steps: \begin{enumerate}
        \item Roll the die once
        \item Roll the die repeatedly until a new number pops up
    \end{enumerate}
    $X = $ total number of rolls $ X_1 + X_2$, where $X_1=$ number of rolls in step one, and $X_2= $ $\sim$ \footnote{$\sim$ means "has distribution"} Geometric ($\frac{5}{6})$ number of rolls in step two. Then $\mathbb{E}X = 1 + \frac{6}{5} = \frac{11}{5}$  
\end{example}
\textbf{Coupon Collector}:\\
Suppose we have $n$ coupons total. $\{1, 2, 3, \dots, n\}$. In each trial, get one uniformly at random. $X =$ number of trials until you get at least one of each.  What is the expected value of $X$\\
Let \\
$X_0 = 1 =$ number of trials to see the first new coupon \\
$X_1 = $ number of trials between seeing the first and second new coupons\\
\dots \\
$X_i = $ number of trials after $\Sum X_{i-1} = $ (number of trials to see $i$ new coupons) to see the $i+1$st new coupon.\\
\dots\\
\\
So our formula is $$\sum_{i=0}^{n-1} \frac{n-i}{n} \approx n\int_1^n\frac{1}{x}dx = n \ln n$$


\subsubsection{Algebra with random variables}
Given random variables $X, Y: S \to \RR$, we defined \begin{enumerate}
    \item $(X+Y)(s) = X(s) + Y(s)$ - SUM
    \item $(cX)(s) = x\cdot X(s)$ where $c \in \RR$ - scalar mult
    \item $XY: S \to \RR$ by $(XY(s) = X(s) + Y(s))$ - Product
\end{enumerate}
\begin{example}
    Suppose we have two independent dice rolls, with: \\
    $X =$ number on first\\
    $Y = $ number on second\\
    $XY = $ product of the two numbers
\end{example}
$\mathbb{E} 1_E1_F = \mathcbb{E}1_{E \cap F} = \mathbb{P}(E\cap F) $\\
$\mathbb{E} 1_E \mathbb{E} 1_F = \mathbb{P}(E)\mathbb{P}(F)$\\
These two are not equal, except for when $E, F$ are independent.
\begin{definition}
    Random variables $X, Y: S \to R$ are \vocab{independent} if $\forall $ $r_1, r_2 \in \mathbb{R}$ the events $\{X= r_1\} , \{Y=r_2\}$ are independent (i.e., $\mathbb{P}(x=r_1 \cap Y=r_2) = \mathbb{P}(X=r_1 \mathbb{P}(Y=r_2)$)
\end{definition}
\begin{theorem}
    If $X, Y$ are independent random variables, then $\mathbb{E}XY = \mathbb{E}X \mathbb{E}Y $
\end{theorem}

\begin{remark}
    Linearity of expectation does not require independence - with sums you don't need independence, but with products you do.
\end{remark}


\textbf{Polynomials}: Given $X, Y : S \to \mathbb{R}$, we can define expressions such as $(X +Y)^2 = X^2 + 2XY + Y^2$



\subsubsection{Variance} 
\textbf{Motivation}: Given $X$, we want to understand how close $X$ "typically" is to $\mathbb{E}X$. 

\begin{definition}
    \vocab{Variance} is defined as the square root of the standard deviation
\end{definition}

\begin{definition}
    If a random variable $X$ has $\mathbb{E}X = \mu_x$, the \vocab{variance} of $X$ denoted $V(X)$ is $$\mathbb{E}(X - \mu_X)^2$$
\end{definition}

\begin{remark}
    The standard deviation stdev$(x) = \sqrt{V(X)}$ means the "typical" deviation from $\mu_X$ 
\end{remark}

\begin{remark}
    Why don't we do this? $\mathbb{E}(X - \mu_X)$
\end{remark}
\\
Answer: because $\mathbb{E}(X - \mu_X) = 0$
\\
Follow up question: Why don't we just compute the absolute values
\\
Answer: Pain to calculate, but also, $\mathbb{E}(X - \mu_X)^2 = \<X-\mu_X, X-\mu_X\>$ in an inner product space. This is the real reason why we square it. (Hidden euclidean geometry)

\begin{theorem}
    If $X$ and $Y$ are independent random variables, $V(X+Y) = V(X) + V(Y)$
\end{theorem}

\begin{corollary}
    The same follows for $n$ pairwise independent random variables
\end{corollary}
The above follow computationally
\newline
\noindent
\Line
\\

\subsection{12.5.2024}
\subsubsection{Markov's Inequality}
Given $S, p: S \to \RR$, $X:S\to \mathbb{R}$.  How close is $X$ to $\mathbb{E}X$, typically?
\begin{theorem}
    If $Y$ is a nonnegative random variable, then for all $t>0$, $\mathbb{P}(Y \geq t) \leq \frac{\mathbb{E}Y}{t}$
\end{theorem}
This tells us that A nonnegative random variable is unlikely to be much larger than its Expected Value.
\begin{example}
    $Y =$ random midterm 2 score. $\mathbb{E}Y = 30$.\\
    Let $t=40$. Markov's inequality tells us that $\mathbb{P}(Y \geq 40) \leq \frac{30}{40} = \frac{3}{4}$.
\end{example}
\begin{proof}
    Let $Y \geq 0$, $t > 0$. 
    \begin{align*}
         \mathbb{E}(Y) &\coloneqq \sum_{r\geq 0} r \mathbb{P}(Y=r)\\
    &=\sum_{r\geq 0, r \geq t}r\mathbb{P}(Y =r) + \sum_{r \geq 0, r<t}r\mahtbb{P}(Y=r)\\
    &\geq \sum_{r\geq 0, r \geq t} r \mathbb{P}(Y=r)\\
    &\geq \sum_{r\geq 0, e \geq t}t\mathbb{P}(Y=r) = t\sum_{r\geq 0, e \geq t}\mathbb{P}(Y=r)\\
    &=t \mathbb{P}(Y\geq t)
    \end{align*}
\end{proof}

\subsubsection{Chebyshev's Inequality}
\begin{theorem}
    If $Y$ is a random variable, $\forall t > 0$, $\mathbb{P} (|Y - \mathbb{E}Y| \leq \frac{V(Y)}{t^2}$
\end{theorem}
\begin{proof}
    Given $Y$, $t>0$, let $\mu_x = \mathbb{E}Y$ and define $Z = (Y - \mu_Y)^2$, which is nonnegative. Notice $\mathbb{E}Z = \mathbb{E}(Y - \mu_Y)^2 = V(Y)$. \\
    By Markov, $\mathbb{P}(Z \geq t^2) \leq \frac{\mathbb{E}(Z)}{t^2} = \frac{V(Y)}{Z}$ \\
    But $\mathbb{P}(Z \geq t^2) = \mathbb{P}((Y-\mu_Y)^2 \geq t^2) = \mathbb{P}(|Y-\mu_Y|\geq t) $, which is Chebyshev
\end{proof}

\begin{example}
    Prototypical Example throughout statistics: Given a coin with unknown bias $q \in [0, 1]$, how can you find $q$? \\
    Idea: Flip a coin $n$ times independently.\\
    Let $X_i =$ \begin{cases}
        $1$ \text{ if }$i$\text{th flip is }$H$\text{ where }$i = 1, \dots, n$\\
        $0$\text{ otherwise}
    \end{cases}
    Define $\hat{q} = \frac{X_1 + X_2 + \dots + X_n}{n} = $ fraction of flips which were $H$.\\ \begin{itemize}
        \item  $\mathbb{E}\hat{q} =\frac{\mathbb{E} X_1 + \mathbb{E}X_2 + \dots + \mathbb{E}X_n}{n} = \frac{q + \dots + q}{n} = q$
        \item \begin{align*}
            V(\hat{q}) &= \mathbb{E}(\frac{X_1 + \dots + X_n}{n})^2 - (\mathbb{E}(X_1+  \dots + X_n))^2\\
            &= \frac{1}{n^2} [\mathbb{E}(X_1 + \dots + X_n)^2 - (\mathbb{E}(X_1 + \dots + X_n))^2]\\
            &= \frac{1}{n^2} V(X_1 + \dots + X_n)\\
            &= \frac{1}{n^2}[V(X_1) + \dots + V(X_n)]\\
            &= \frac{nq(1-q)}{n^2}\\
            &= \frac{q(1-q)}{n} \leq \frac{1}{4n} \text{ for all } q \in [0, 1]
        \end{align*}
    \end{itemize}
    By Chebyshev: $$\mathbb{P}(|\hat{q} - q| \geq t ) \leq \frac{V}(\hat{q}){t^2} \leq \frac{1}{4nt^2}$$
        For $t = \frac{1}{20}$, $n=1000$, $\mathbb{P}(\hat{q} - q| \geq \frac{1}{20}) \leq \frac{1}{4 \cdot 1000 \cdit \frac{1}{400}} = \frac{1}{10}$.  Therefore, with $90 \%$ probability, $\hat{q}$ is within $\frac{1}{20}$ of the bias.
\end{example}

\begin{remark}
    \bullet \text{ In general, $V(xC) = c^2 V(X)$ for $c \in \mathbb{R}$.}
\end{remark}
\subsubsection{Law of Large Numbers}
\begin{theorem}
    If $X_1, \dots, X_n$ are independent random variables with the same distribution, $\mathbb{E}X<\infty$, $V(X) < \infty$, for all $t>0$, $$\lim_{n \to \infty } \mathbb{P}(|\frac{X_1 + \dots + X_n}{n} - \frac{\mathbb{E}X_1 + \dots X_n}{n}| \geq t) = 0$$
    
\end{theorem}



\newline
\noindent
\Line
\end{document}